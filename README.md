# writing-homework  

## Description  

 This project contains writing homework of [**DS1003, NYU**](https://nyu-ds1003.github.io/spring2021/#resources). Up to now, I have finished the former four homework and all of them are hand-written. All these writing homework will be converted to latex
format in the near future.  
This project is still ongoing now.  

## Brief Introduction to Every Homework  

### Homework1  

(1) Mathematical fundamentals: Linear algebra and probability theory.  
(2) Matrix Calculus: Reformulate functions by matrix operation to get a compact expression and utilize vectorization.  
(3) Bayes Prediction Functions: Derive Bayes prediction functions for various loss functions.  
(4) Statistical Learning Theory: Excess Risk Decomposition, regularization, overfit and underfit.  

### Homework2  

(1) Coordinate Descent: Derive Shooting Algorithm for Lasso regression.  
(2) Properties of Lasso Regression: Biggest regularization parameter and distribution of weight parameter.  

### Homework3  

(1) Subgradient: A property of subgradient of max function.  
(2) Perceptron Algorithm: Derive of subgradient descent algorithm for Perceptron.  
(3) Derivation of Pegasos Algorithm: Utilize stochastic subgradient descent to optimize SVM.  

### Homework4  

(1) Kernel Method: Derive kernelized form of Ridge Regression and compute optimal parameters.  
(2) Kernelized Pegasos: Derive stochastic subgradient descent method for kernelized SVM.  
(3) Representer Theorem: Prove this.  
(4) Ivanov Regularization and Tikhonov Regularization: Prove the equivalence between them.  

### Homework5  

**Still ongoing.**
